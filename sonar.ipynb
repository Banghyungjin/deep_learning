{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ed2c2aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0286</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0277</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.1201</td>\n",
       "      <td>0.1833</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.3039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0317</td>\n",
       "      <td>0.0956</td>\n",
       "      <td>0.1321</td>\n",
       "      <td>0.1408</td>\n",
       "      <td>0.1674</td>\n",
       "      <td>0.1710</td>\n",
       "      <td>0.0731</td>\n",
       "      <td>0.1401</td>\n",
       "      <td>0.2083</td>\n",
       "      <td>0.3513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.0248</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0519</td>\n",
       "      <td>0.0548</td>\n",
       "      <td>0.0842</td>\n",
       "      <td>0.0319</td>\n",
       "      <td>0.1158</td>\n",
       "      <td>0.0922</td>\n",
       "      <td>0.1027</td>\n",
       "      <td>0.0613</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.2838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.0475</td>\n",
       "      <td>0.0647</td>\n",
       "      <td>0.0591</td>\n",
       "      <td>0.0753</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0684</td>\n",
       "      <td>0.1487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0173</td>\n",
       "      <td>0.0347</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.0671</td>\n",
       "      <td>0.1056</td>\n",
       "      <td>0.0697</td>\n",
       "      <td>0.0962</td>\n",
       "      <td>0.0251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "5  0.0286  0.0453  0.0277  0.0174  0.0384  0.0990  0.1201  0.1833  0.2105   \n",
       "6  0.0317  0.0956  0.1321  0.1408  0.1674  0.1710  0.0731  0.1401  0.2083   \n",
       "7  0.0519  0.0548  0.0842  0.0319  0.1158  0.0922  0.1027  0.0613  0.1465   \n",
       "8  0.0223  0.0375  0.0484  0.0475  0.0647  0.0591  0.0753  0.0098  0.0684   \n",
       "9  0.0164  0.0173  0.0347  0.0070  0.0187  0.0671  0.1056  0.0697  0.0962   \n",
       "\n",
       "       9   ...      51      52      53      54      55      56      57  \\\n",
       "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "5  0.3039  ...  0.0045  0.0014  0.0038  0.0013  0.0089  0.0057  0.0027   \n",
       "6  0.3513  ...  0.0201  0.0248  0.0131  0.0070  0.0138  0.0092  0.0143   \n",
       "7  0.2838  ...  0.0081  0.0120  0.0045  0.0121  0.0097  0.0085  0.0047   \n",
       "8  0.1487  ...  0.0145  0.0128  0.0145  0.0058  0.0049  0.0065  0.0093   \n",
       "9  0.0251  ...  0.0090  0.0223  0.0179  0.0084  0.0068  0.0032  0.0035   \n",
       "\n",
       "       58      59  60  \n",
       "0  0.0090  0.0032   R  \n",
       "1  0.0052  0.0044   R  \n",
       "2  0.0095  0.0078   R  \n",
       "3  0.0040  0.0117   R  \n",
       "4  0.0107  0.0094   R  \n",
       "5  0.0051  0.0062   R  \n",
       "6  0.0036  0.0103   R  \n",
       "7  0.0048  0.0053   R  \n",
       "8  0.0059  0.0022   R  \n",
       "9  0.0056  0.0040   R  \n",
       "\n",
       "[10 rows x 61 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "df = pd.read_csv('sonar.csv', header = None)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "740c1c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2560 - accuracy: 0.3867\n",
      "Epoch 2/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2421 - accuracy: 0.6966\n",
      "Epoch 3/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2322 - accuracy: 0.7533\n",
      "Epoch 4/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2240 - accuracy: 0.7824\n",
      "Epoch 5/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2082 - accuracy: 0.8128\n",
      "Epoch 6/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2040 - accuracy: 0.7337\n",
      "Epoch 7/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1811 - accuracy: 0.7648\n",
      "Epoch 8/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1809 - accuracy: 0.7338\n",
      "Epoch 9/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1819 - accuracy: 0.7220\n",
      "Epoch 10/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1654 - accuracy: 0.7908\n",
      "Epoch 11/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1603 - accuracy: 0.7995\n",
      "Epoch 12/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1545 - accuracy: 0.7745\n",
      "Epoch 13/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1470 - accuracy: 0.8474\n",
      "Epoch 14/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1414 - accuracy: 0.8074\n",
      "Epoch 15/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1411 - accuracy: 0.8247\n",
      "Epoch 16/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1350 - accuracy: 0.8658\n",
      "Epoch 17/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1599 - accuracy: 0.8042\n",
      "Epoch 18/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1322 - accuracy: 0.8224\n",
      "Epoch 19/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1446 - accuracy: 0.7990\n",
      "Epoch 20/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1112 - accuracy: 0.8701\n",
      "Epoch 21/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1217 - accuracy: 0.8483\n",
      "Epoch 22/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1397 - accuracy: 0.8197\n",
      "Epoch 23/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1274 - accuracy: 0.8027\n",
      "Epoch 24/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1242 - accuracy: 0.8495\n",
      "Epoch 25/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1146 - accuracy: 0.8666\n",
      "Epoch 26/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1123 - accuracy: 0.8737\n",
      "Epoch 27/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1078 - accuracy: 0.8393\n",
      "Epoch 28/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1244 - accuracy: 0.8481\n",
      "Epoch 29/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1045 - accuracy: 0.9117\n",
      "Epoch 30/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1186 - accuracy: 0.8459\n",
      "Epoch 31/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1048 - accuracy: 0.8725\n",
      "Epoch 32/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0973 - accuracy: 0.9149\n",
      "Epoch 33/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0995 - accuracy: 0.8867\n",
      "Epoch 34/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1124 - accuracy: 0.8707\n",
      "Epoch 35/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1045 - accuracy: 0.8710\n",
      "Epoch 36/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1044 - accuracy: 0.8645\n",
      "Epoch 37/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1045 - accuracy: 0.8736\n",
      "Epoch 38/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0865 - accuracy: 0.9092\n",
      "Epoch 39/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0852 - accuracy: 0.9032\n",
      "Epoch 40/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0808 - accuracy: 0.9115\n",
      "Epoch 41/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0958 - accuracy: 0.8411\n",
      "Epoch 42/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0954 - accuracy: 0.9072\n",
      "Epoch 43/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0982 - accuracy: 0.8759\n",
      "Epoch 44/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0834 - accuracy: 0.9186\n",
      "Epoch 45/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0701 - accuracy: 0.9388\n",
      "Epoch 46/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0817 - accuracy: 0.9331\n",
      "Epoch 47/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0880 - accuracy: 0.9007\n",
      "Epoch 48/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0866 - accuracy: 0.8758\n",
      "Epoch 49/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0947 - accuracy: 0.8789\n",
      "Epoch 50/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0657 - accuracy: 0.9357\n",
      "Epoch 51/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1013 - accuracy: 0.8808\n",
      "Epoch 52/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0737 - accuracy: 0.9225\n",
      "Epoch 53/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0922 - accuracy: 0.8923\n",
      "Epoch 54/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0894 - accuracy: 0.8603\n",
      "Epoch 55/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0764 - accuracy: 0.9281\n",
      "Epoch 56/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0656 - accuracy: 0.9158\n",
      "Epoch 57/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0642 - accuracy: 0.9276\n",
      "Epoch 58/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0672 - accuracy: 0.9338\n",
      "Epoch 59/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0668 - accuracy: 0.9216\n",
      "Epoch 60/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0592 - accuracy: 0.9472\n",
      "Epoch 61/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0734 - accuracy: 0.9029\n",
      "Epoch 62/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0679 - accuracy: 0.9538\n",
      "Epoch 63/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0813 - accuracy: 0.8888\n",
      "Epoch 64/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0596 - accuracy: 0.9397\n",
      "Epoch 65/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0503 - accuracy: 0.9520\n",
      "Epoch 66/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0668 - accuracy: 0.9370\n",
      "Epoch 67/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0569 - accuracy: 0.9508\n",
      "Epoch 68/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0573 - accuracy: 0.9175\n",
      "Epoch 69/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0438 - accuracy: 0.9543\n",
      "Epoch 70/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0428 - accuracy: 0.9573\n",
      "Epoch 71/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0562 - accuracy: 0.9484\n",
      "Epoch 72/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0546 - accuracy: 0.9196\n",
      "Epoch 73/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0410 - accuracy: 0.9757\n",
      "Epoch 74/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0592 - accuracy: 0.9259\n",
      "Epoch 75/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0417 - accuracy: 0.9795\n",
      "Epoch 76/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0314 - accuracy: 0.9852\n",
      "Epoch 77/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0669 - accuracy: 0.9286\n",
      "Epoch 78/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0494 - accuracy: 0.9620\n",
      "Epoch 79/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0529 - accuracy: 0.9422\n",
      "Epoch 80/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0484 - accuracy: 0.9712\n",
      "Epoch 81/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0327 - accuracy: 0.9888\n",
      "Epoch 82/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0484 - accuracy: 0.9474\n",
      "Epoch 83/130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0367 - accuracy: 0.9856\n",
      "Epoch 84/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0431 - accuracy: 0.9773\n",
      "Epoch 85/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0368 - accuracy: 0.9697\n",
      "Epoch 86/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0293 - accuracy: 0.9863\n",
      "Epoch 87/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0290 - accuracy: 0.9931\n",
      "Epoch 88/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0377 - accuracy: 0.9784\n",
      "Epoch 89/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0269 - accuracy: 0.9951\n",
      "Epoch 90/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0281 - accuracy: 0.9864\n",
      "Epoch 91/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0344 - accuracy: 0.9827\n",
      "Epoch 92/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0315 - accuracy: 0.9973\n",
      "Epoch 93/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0276 - accuracy: 0.9834\n",
      "Epoch 94/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0270 - accuracy: 0.9843\n",
      "Epoch 95/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0258 - accuracy: 0.9915\n",
      "Epoch 96/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0275 - accuracy: 0.9873\n",
      "Epoch 97/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0171 - accuracy: 0.9995\n",
      "Epoch 98/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0247 - accuracy: 0.9903\n",
      "Epoch 99/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0187 - accuracy: 0.9909\n",
      "Epoch 100/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0326 - accuracy: 0.9834\n",
      "Epoch 101/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0221 - accuracy: 0.9835\n",
      "Epoch 102/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0216 - accuracy: 0.9808\n",
      "Epoch 103/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0273 - accuracy: 0.9707\n",
      "Epoch 104/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0162 - accuracy: 0.9877\n",
      "Epoch 105/130\n",
      "29/29 [==============================] - 0s 997us/step - loss: 0.0130 - accuracy: 0.9970\n",
      "Epoch 106/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0200 - accuracy: 0.9906\n",
      "Epoch 107/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0173 - accuracy: 0.9950\n",
      "Epoch 108/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0154 - accuracy: 0.9906\n",
      "Epoch 109/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0162 - accuracy: 1.0000\n",
      "Epoch 110/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0170 - accuracy: 1.0000\n",
      "Epoch 111/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0173 - accuracy: 1.0000\n",
      "Epoch 112/130\n",
      "29/29 [==============================] - 0s 999us/step - loss: 0.0162 - accuracy: 1.0000\n",
      "Epoch 113/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0194 - accuracy: 0.9950\n",
      "Epoch 114/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0162 - accuracy: 0.9934\n",
      "Epoch 115/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0100 - accuracy: 1.0000\n",
      "Epoch 116/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0095 - accuracy: 1.0000\n",
      "Epoch 117/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0104 - accuracy: 1.0000\n",
      "Epoch 118/130\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 1.00 - 0s 1ms/step - loss: 0.0181 - accuracy: 1.0000\n",
      "Epoch 119/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0089 - accuracy: 1.0000\n",
      "Epoch 120/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 121/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0122 - accuracy: 0.9929\n",
      "Epoch 122/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0117 - accuracy: 1.0000\n",
      "Epoch 123/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 124/130\n",
      "29/29 [==============================] - 0s 997us/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 125/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0120 - accuracy: 1.0000\n",
      "Epoch 126/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0099 - accuracy: 0.9953\n",
      "Epoch 127/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 128/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 129/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 130/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0074 - accuracy: 1.0000\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0505 - accuracy: 0.9375\n",
      "\n",
      "Accuracy : 0.9375\n"
     ]
    }
   ],
   "source": [
    "dataset = df.values\n",
    "X = dataset[:,0:60]\n",
    "X = np.asarray(X).astype(np.float32)\n",
    "\n",
    "Y_obj = dataset[:,60]\n",
    "\n",
    "e = LabelEncoder()\n",
    "e.fit(Y_obj)\n",
    "Y = e.transform(Y_obj)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state=3)\n",
    "model = Sequential()\n",
    "model.add(Dense(24, input_dim = 60, activation='relu'))\n",
    "model.add(Dense(10, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.fit(X_train, Y_train, epochs = 130, batch_size = 5)\n",
    "\n",
    "print('\\nAccuracy : %.4f'% (model.evaluate(X,Y)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94fd6deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e8ff6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07323b97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9c772c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
