{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccd5ca55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*- coding: utf-8 -*-\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score,confusion_matrix, precision_recall_curve\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import numpy\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import graphviz\n",
    "import time\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd38e094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 값 설정\n",
    "seed = 0\n",
    "numpy.random.seed(seed)\n",
    "tf.random.set_seed(3)\n",
    "df = pd.read_csv(\"creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d79f7af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7ddfce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 세트 Null 값 갯수 \n",
      " Time      0\n",
      "V1        0\n",
      "V2        0\n",
      "V3        0\n",
      "V4        0\n",
      "V5        0\n",
      "V6        0\n",
      "V7        0\n",
      "V8        0\n",
      "V9        0\n",
      "V10       0\n",
      "V11       0\n",
      "V12       0\n",
      "V13       0\n",
      "V14       0\n",
      "V15       0\n",
      "V16       0\n",
      "V17       0\n",
      "V18       0\n",
      "V19       0\n",
      "V20       0\n",
      "V21       0\n",
      "V22       0\n",
      "V23       0\n",
      "V24       0\n",
      "V25       0\n",
      "V26       0\n",
      "V27       0\n",
      "V28       0\n",
      "Amount    0\n",
      "Class     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('데이터 세트 Null 값 갯수 \\n',df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f22c503",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CSV 데이터 종속, 독립 변수 분할\n",
    "dataset = df.values\n",
    "X = dataset[:,1:30]\n",
    "\n",
    "Y = dataset[:,30]       #종속변수\n",
    "#훈련, 테스트 데이터 분할\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.15, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7143e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 구조 생성\n",
    "model = Sequential()\n",
    "model.add(Dense(30,  input_dim=29, activation='relu'))\n",
    "model.add(Dense(15, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e6c2829",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1937/1937 [==============================] - 4s 2ms/step - loss: 0.0652 - accuracy: 0.9895 - val_loss: 0.0253 - val_accuracy: 0.9987\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02526, saving model to ./model\\01-0.0253.hdf5\n",
      "Epoch 2/200\n",
      "1937/1937 [==============================] - 3s 1ms/step - loss: 0.0084 - accuracy: 0.9994 - val_loss: 0.0078 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02526 to 0.00775, saving model to ./model\\02-0.0078.hdf5\n",
      "Epoch 3/200\n",
      "1937/1937 [==============================] - 3s 1ms/step - loss: 0.0079 - accuracy: 0.9993 - val_loss: 0.0077 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00775 to 0.00769, saving model to ./model\\03-0.0077.hdf5\n",
      "Epoch 4/200\n",
      "1937/1937 [==============================] - 3s 1ms/step - loss: 0.0049 - accuracy: 0.9994 - val_loss: 0.0065 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00769 to 0.00651, saving model to ./model\\04-0.0065.hdf5\n",
      "Epoch 5/200\n",
      "1937/1937 [==============================] - 3s 1ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.0278 - val_accuracy: 0.9987\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00651\n",
      "Epoch 6/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0082 - accuracy: 0.9993 - val_loss: 0.0057 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00651 to 0.00565, saving model to ./model\\06-0.0057.hdf5\n",
      "Epoch 7/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0044 - accuracy: 0.9994 - val_loss: 0.0053 - val_accuracy: 0.9991\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00565 to 0.00531, saving model to ./model\\07-0.0053.hdf5\n",
      "Epoch 8/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0048 - accuracy: 0.9994 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00531 to 0.00463, saving model to ./model\\08-0.0046.hdf5\n",
      "Epoch 9/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.0104 - val_accuracy: 0.9986\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00463\n",
      "Epoch 10/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 0.0053 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00463\n",
      "Epoch 11/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.0048 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00463\n",
      "Epoch 12/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 0.0048 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.00463\n",
      "Epoch 13/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.0052 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.00463\n",
      "Epoch 14/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.0044 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.00463 to 0.00444, saving model to ./model\\14-0.0044.hdf5\n",
      "Epoch 15/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.0040 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.00444 to 0.00399, saving model to ./model\\15-0.0040.hdf5\n",
      "Epoch 16/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 0.0042 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.00399\n",
      "Epoch 17/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0023 - accuracy: 0.9997 - val_loss: 0.0037 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.00399 to 0.00375, saving model to ./model\\17-0.0037.hdf5\n",
      "Epoch 18/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.0044 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.00375\n",
      "Epoch 19/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.0044 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.00375\n",
      "Epoch 20/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.0046 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.00375\n",
      "Epoch 21/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.0044 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.00375\n",
      "Epoch 22/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.0038 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.00375\n",
      "Epoch 23/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.0048 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.00375\n",
      "Epoch 24/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.0042 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.00375\n",
      "Epoch 25/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.0043 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.00375\n",
      "Epoch 26/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.0047 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.00375\n",
      "Epoch 27/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.0059 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.00375\n",
      "Epoch 28/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0041 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.00375\n",
      "Epoch 29/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.0042 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.00375\n",
      "Epoch 30/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.0056 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.00375\n",
      "Epoch 31/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.0062 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.00375\n",
      "Epoch 32/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0041 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.00375\n",
      "Epoch 33/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0046 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.00375\n",
      "Epoch 34/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0041 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.00375\n",
      "Epoch 35/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0059 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.00375\n",
      "Epoch 36/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0045 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.00375\n",
      "Epoch 37/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.0046 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.00375\n",
      "Epoch 38/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.0042 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.00375\n",
      "Epoch 39/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0041 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.00375\n",
      "Epoch 40/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0056 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.00375\n",
      "Epoch 41/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0045 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.00375\n",
      "Epoch 42/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0045 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.00375\n",
      "Epoch 43/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0051 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.00375\n",
      "Epoch 44/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0049 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.00375\n",
      "Epoch 45/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0056 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.00375\n",
      "Epoch 46/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0043 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.00375\n",
      "Epoch 47/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0046 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.00375\n",
      "Epoch 48/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0056 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.00375\n",
      "Epoch 49/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0048 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.00375\n",
      "Epoch 50/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0062 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.00375\n",
      "Epoch 51/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0049 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.00375\n",
      "Epoch 52/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0058 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.00375\n",
      "Epoch 53/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0054 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.00375\n",
      "Epoch 54/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 9.9266e-04 - accuracy: 0.9998 - val_loss: 0.0048 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.00375\n",
      "Epoch 55/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0055 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.00375\n",
      "Epoch 56/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0055 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.00375\n",
      "Epoch 57/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0058 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.00375\n",
      "Epoch 58/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0064 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.00375\n",
      "Epoch 59/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0062 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.00375\n",
      "Epoch 60/200\n",
      "1937/1937 [==============================] - 3s 1ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0065 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.00375\n",
      "Epoch 61/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0066 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.00375\n",
      "Epoch 62/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0084 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.00375\n",
      "Epoch 63/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0078 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.00375\n",
      "Epoch 64/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0068 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.00375\n",
      "Epoch 65/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0082 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.00375\n",
      "Epoch 66/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0054 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.00375\n",
      "Epoch 67/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0055 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.00375\n",
      "Epoch 68/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 9.4130e-04 - accuracy: 0.9998 - val_loss: 0.0066 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.00375\n",
      "Epoch 69/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0064 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.00375\n",
      "Epoch 70/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0093 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.00375\n",
      "Epoch 71/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0063 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.00375\n",
      "Epoch 72/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0066 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.00375\n",
      "Epoch 73/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0073 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.00375\n",
      "Epoch 74/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 9.5098e-04 - accuracy: 0.9998 - val_loss: 0.0064 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.00375\n",
      "Epoch 75/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0065 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.00375\n",
      "Epoch 76/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0064 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.00375\n",
      "Epoch 77/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0059 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.00375\n",
      "Epoch 78/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0081 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.00375\n",
      "Epoch 79/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.0068 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.00375\n",
      "Epoch 80/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0066 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.00375\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1937/1937 [==============================] - 3s 2ms/step - loss: 9.0909e-04 - accuracy: 0.9998 - val_loss: 0.0053 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.00375\n",
      "Epoch 82/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0061 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.00375\n",
      "Epoch 83/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 9.4534e-04 - accuracy: 0.9998 - val_loss: 0.0064 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.00375\n",
      "Epoch 84/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0065 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.00375\n",
      "Epoch 85/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0067 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.00375\n",
      "Epoch 86/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0065 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.00375\n",
      "Epoch 87/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0067 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.00375\n",
      "Epoch 88/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 9.0282e-04 - accuracy: 0.9998 - val_loss: 0.0059 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.00375\n",
      "Epoch 89/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 7.2763e-04 - accuracy: 0.9998 - val_loss: 0.0062 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.00375\n",
      "Epoch 90/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 8.1573e-04 - accuracy: 0.9998 - val_loss: 0.0062 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.00375\n",
      "Epoch 91/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0061 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.00375\n",
      "Epoch 92/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 9.4860e-04 - accuracy: 0.9997 - val_loss: 0.0070 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.00375\n",
      "Epoch 93/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0057 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.00375\n",
      "Epoch 94/200\n",
      "1937/1937 [==============================] - 3s 1ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0069 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.00375\n",
      "Epoch 95/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0063 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.00375\n",
      "Epoch 96/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0067 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.00375\n",
      "Epoch 97/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0070 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.00375\n",
      "Epoch 98/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0069 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.00375\n",
      "Epoch 99/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0077 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.00375\n",
      "Epoch 100/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0074 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.00375\n",
      "Epoch 101/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0071 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.00375\n",
      "Epoch 102/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 9.9601e-04 - accuracy: 0.9998 - val_loss: 0.0073 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.00375\n",
      "Epoch 103/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 9.0893e-04 - accuracy: 0.9999 - val_loss: 0.0069 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.00375\n",
      "Epoch 104/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 8.4421e-04 - accuracy: 0.9998 - val_loss: 0.0083 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.00375\n",
      "Epoch 105/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0067 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.00375\n",
      "Epoch 106/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0066 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.00375\n",
      "Epoch 107/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 8.8654e-04 - accuracy: 0.9998 - val_loss: 0.0070 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.00375\n",
      "Epoch 108/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0069 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.00375\n",
      "Epoch 109/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0072 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.00375\n",
      "Epoch 110/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 9.2602e-04 - accuracy: 0.9998 - val_loss: 0.0066 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.00375\n",
      "Epoch 111/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0080 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.00375\n",
      "Epoch 112/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0077 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.00375\n",
      "Epoch 113/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0065 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.00375\n",
      "Epoch 114/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 8.1886e-04 - accuracy: 0.9998 - val_loss: 0.0066 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.00375\n",
      "Epoch 115/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 8.0624e-04 - accuracy: 0.9999 - val_loss: 0.0074 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.00375\n",
      "Epoch 116/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 9.1307e-04 - accuracy: 0.9998 - val_loss: 0.0086 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.00375\n",
      "Epoch 117/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0066 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.00375\n"
     ]
    }
   ],
   "source": [
    "#모델 컴파일 및 학습\n",
    "model.compile(loss='binary_crossentropy',\n",
    "          optimizer='adam',\n",
    "          metrics=['accuracy'])\n",
    "MODEL_DIR = './credit_model/'\n",
    "\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "    \n",
    "modelpath = './model/{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "checkpointer = ModelCheckpoint(filepath = modelpath, monitor = 'val_loss', verbose = 1, save_best_only=True)\n",
    "\n",
    "early_stopping_callback= EarlyStopping(monitor= 'val_loss', patience = 100)\n",
    "\n",
    "history = model.fit(X_train, Y_train, validation_split=0.2, epochs=200, batch_size=100, callbacks = [early_stopping_callback,checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6498a3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1336/1336 [==============================] - 1s 898us/step - loss: 0.0078 - accuracy: 0.9995\n",
      "[0.007825056090950966, 0.9994850158691406]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60307cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e2a27cc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0015686750 0.0\n",
      "0.0000000005 0.0\n",
      "0.0003870428 0.0\n",
      "0.0000000048 0.0\n",
      "0.0000029293 0.0\n",
      "0.0000000153 0.0\n",
      "0.0000000030 0.0\n",
      "0.0000000002 0.0\n",
      "0.0000000000 0.0\n",
      "0.0000000002 0.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print('%.10f' % predict[i], Y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1eec7d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(Y[541])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "236520e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.] 1.0 right\n",
      "[0.9969686] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.99774724] 1.0 right\n",
      "[0.9134822] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.68666625] 1.0 right\n",
      "[0.91822374] 1.0 right\n",
      "[0.99920624] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9847075] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9999964] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9923367] 1.0 right\n",
      "[0.9304861] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.99991953] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.5994768] 0.0 wrong\n",
      "[0.9956496] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9999281] 1.0 right\n",
      "[0.627624] 1.0 right\n",
      "[0.99961287] 1.0 right\n",
      "[0.9998023] 1.0 right\n",
      "[0.99848765] 1.0 right\n",
      "[0.99994683] 1.0 right\n",
      "[0.99997455] 1.0 right\n",
      "[0.9999889] 1.0 right\n",
      "[0.99999523] 1.0 right\n",
      "[0.999998] 1.0 right\n",
      "[0.99999917] 1.0 right\n",
      "[0.99999964] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.99999976] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9042937] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9999981] 1.0 right\n",
      "[0.9998379] 1.0 right\n",
      "[0.9867314] 1.0 right\n",
      "[0.69223845] 1.0 right\n",
      "[0.999989] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9576211] 1.0 right\n",
      "[0.9810226] 1.0 right\n",
      "[0.92827773] 1.0 right\n",
      "[0.9999997] 1.0 right\n",
      "[0.9999945] 1.0 right\n",
      "[0.99999917] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9999992] 1.0 right\n",
      "[0.99999845] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9978063] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9999988] 1.0 right\n",
      "[0.998166] 1.0 right\n",
      "[0.9514666] 1.0 right\n",
      "[0.7357048] 1.0 right\n",
      "[0.999747] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.99950397] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9997207] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.99999857] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.99993134] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9998611] 1.0 right\n",
      "[0.9932325] 1.0 right\n",
      "[0.8044137] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9983321] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.99912727] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9997513] 1.0 right\n",
      "[0.9999993] 1.0 right\n",
      "[0.998664] 1.0 right\n",
      "[0.99868023] 1.0 right\n",
      "[0.5982767] 0.0 wrong\n",
      "[0.996405] 1.0 right\n",
      "[0.99999434] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.994428] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.63209915] 0.0 wrong\n",
      "[0.5315137] 0.0 wrong\n",
      "[0.995726] 1.0 right\n",
      "[0.9568181] 1.0 right\n",
      "[0.97962236] 1.0 right\n",
      "[0.9915125] 1.0 right\n",
      "[0.99649465] 1.0 right\n",
      "[0.99855816] 1.0 right\n",
      "[0.9999995] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9997144] 1.0 right\n",
      "[0.999949] 1.0 right\n",
      "[0.9644095] 1.0 right\n",
      "[0.99977636] 1.0 right\n",
      "[0.99999744] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9997018] 1.0 right\n",
      "[0.99945754] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9999516] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.99999845] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.99992746] 1.0 right\n",
      "[0.99962175] 1.0 right\n",
      "[0.99687135] 1.0 right\n",
      "[0.99795115] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9544937] 1.0 right\n",
      "[0.9999994] 1.0 right\n",
      "[0.99792844] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.99855757] 1.0 right\n",
      "[0.99999976] 1.0 right\n",
      "[0.9999297] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.99997187] 1.0 right\n",
      "[0.9811837] 1.0 right\n",
      "[0.99999094] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.99701995] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9999724] 1.0 right\n",
      "[0.9999895] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9266794] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.99774] 1.0 right\n",
      "[0.9999871] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.999992] 1.0 right\n",
      "[0.99720764] 1.0 right\n",
      "[0.99993] 1.0 right\n",
      "[0.99984145] 1.0 right\n",
      "[0.99110353] 1.0 right\n",
      "[0.9999839] 1.0 right\n",
      "[0.9979374] 1.0 right\n",
      "[0.99999547] 1.0 right\n",
      "[0.99346256] 1.0 right\n",
      "[0.9993043] 1.0 right\n",
      "[0.98181826] 0.0 wrong\n",
      "[0.9629811] 1.0 right\n",
      "[0.9181464] 1.0 right\n",
      "[0.95859575] 1.0 right\n",
      "[0.9710111] 1.0 right\n",
      "[0.99871886] 1.0 right\n",
      "[0.99999326] 1.0 right\n",
      "[0.99902767] 1.0 right\n",
      "[0.999998] 1.0 right\n",
      "[0.9999913] 1.0 right\n",
      "[0.9999937] 1.0 right\n",
      "[0.9995637] 1.0 right\n",
      "[0.99999917] 1.0 right\n",
      "[0.9999234] 1.0 right\n",
      "[0.99998695] 1.0 right\n",
      "[0.9999998] 1.0 right\n",
      "[0.99972224] 1.0 right\n",
      "[0.9999988] 1.0 right\n",
      "[0.9964043] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 0.0 wrong\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9511357] 1.0 right\n",
      "[0.99924606] 1.0 right\n",
      "[0.9989939] 1.0 right\n",
      "[0.999869] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.88264346] 1.0 right\n",
      "[0.99996436] 0.0 wrong\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9999976] 1.0 right\n",
      "[0.9999912] 1.0 right\n",
      "[0.9818641] 0.0 wrong\n",
      "[0.9855226] 1.0 right\n",
      "[0.9999975] 1.0 right\n",
      "[0.9986041] 1.0 right\n",
      "[0.9992224] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9852995] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9999999] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.999994] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9959656] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9992069] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.99957085] 1.0 right\n",
      "[0.9994954] 1.0 right\n",
      "[0.9993564] 1.0 right\n",
      "[0.9908554] 1.0 right\n",
      "[0.8266377] 0.0 wrong\n",
      "[1.] 1.0 right\n",
      "[0.80126894] 1.0 right\n",
      "[0.9588119] 0.0 wrong\n",
      "[0.9969585] 0.0 wrong\n",
      "[0.9916783] 1.0 right\n",
      "[0.9832828] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.99723446] 0.0 wrong\n",
      "[0.99646795] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9998143] 1.0 right\n",
      "[0.99999154] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.99999964] 1.0 right\n",
      "[0.9999502] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 0.0 wrong\n",
      "[1.] 1.0 right\n",
      "[0.99875116] 1.0 right\n",
      "[0.9999993] 0.0 wrong\n",
      "[1.] 1.0 right\n",
      "[0.9999858] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.99995196] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.99999976] 1.0 right\n",
      "[0.5324379] 0.0 wrong\n",
      "[1.] 1.0 right\n",
      "[0.9205966] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9977102] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.8826353] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.99978435] 1.0 right\n",
      "[0.9670899] 0.0 wrong\n",
      "[1.] 1.0 right\n",
      "[0.76575613] 0.0 wrong\n",
      "[0.99886745] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.8920668] 1.0 right\n",
      "[0.99999726] 1.0 right\n",
      "[0.99837005] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.80422866] 0.0 wrong\n",
      "[1.] 1.0 right\n",
      "[0.5071074] 0.0 wrong\n",
      "[0.8989012] 1.0 right\n",
      "[0.99706846] 1.0 right\n",
      "[0.9999457] 1.0 right\n",
      "[0.9999995] 1.0 right\n",
      "[0.99477285] 1.0 right\n",
      "[0.9989521] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9999995] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.99654126] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.76933163] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9999653] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.73380494] 0.0 wrong\n",
      "[0.66313285] 1.0 right\n",
      "[0.92189455] 1.0 right\n",
      "[0.9999908] 1.0 right\n",
      "[0.9961889] 1.0 right\n",
      "[0.9999996] 0.0 wrong\n",
      "[0.9999994] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.99999976] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.99968576] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9999995] 1.0 right\n",
      "[0.96594715] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9999533] 1.0 right\n",
      "[0.7882011] 1.0 right\n",
      "[0.9954537] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9974523] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.99998236] 1.0 right\n",
      "[0.9991852] 1.0 right\n",
      "[0.9958954] 1.0 right\n",
      "[0.99793637] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.99703777] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9996385] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9973575] 0.0 wrong\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.99803436] 1.0 right\n",
      "[0.9826613] 0.0 wrong\n",
      "[0.98902464] 1.0 right\n",
      "[0.5181676] 1.0 right\n",
      "[0.9999765] 1.0 right\n",
      "[0.9999726] 1.0 right\n",
      "[0.99995553] 1.0 right\n",
      "[0.99999475] 1.0 right\n",
      "[0.999808] 1.0 right\n",
      "433 23\n"
     ]
    }
   ],
   "source": [
    "r_count = 0\n",
    "w_count = 0\n",
    "for index, i in enumerate(predict):\n",
    "    if i > 0.5:\n",
    "        if (Y[index] == 1.0):\n",
    "            r_count += 1\n",
    "            print(i, Y[index], 'right')\n",
    "        else :\n",
    "            w_count += 1\n",
    "            print(i, Y[index], 'wrong')\n",
    "print(r_count, w_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4aed693d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 [1.] right\n",
      "1.0 [0.08570296] wrong\n",
      "1.0 [0.9969686] right\n",
      "1.0 [0.301267] wrong\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.99774724] right\n",
      "1.0 [0.9134822] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.68666625] right\n",
      "1.0 [0.91822374] right\n",
      "1.0 [0.99920624] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.9847075] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.9999964] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.9923367] right\n",
      "1.0 [0.9304861] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.99991953] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.09426075] wrong\n",
      "1.0 [0.00519726] wrong\n",
      "1.0 [0.9956496] right\n",
      "1.0 [0.09604016] wrong\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.9999281] right\n",
      "1.0 [0.627624] right\n",
      "1.0 [0.99961287] right\n",
      "1.0 [0.9998023] right\n",
      "1.0 [0.99848765] right\n",
      "1.0 [0.99994683] right\n",
      "1.0 [0.99997455] right\n",
      "1.0 [0.9999889] right\n",
      "1.0 [0.99999523] right\n",
      "1.0 [0.999998] right\n",
      "1.0 [0.99999917] right\n",
      "1.0 [0.99999964] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.99999976] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.9042937] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.9999981] right\n",
      "1.0 [0.9998379] right\n",
      "1.0 [0.9867314] right\n",
      "1.0 [0.69223845] right\n",
      "1.0 [0.999989] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.9576211] right\n",
      "1.0 [0.02022946] wrong\n",
      "1.0 [0.9810226] right\n",
      "1.0 [0.92827773] right\n",
      "1.0 [0.9999997] right\n",
      "1.0 [3.4477553e-13] wrong\n",
      "1.0 [0.9999945] right\n",
      "1.0 [0.99999917] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.9999992] right\n",
      "1.0 [0.99999845] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.9978063] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.9999988] right\n",
      "1.0 [0.998166] right\n",
      "1.0 [0.9514666] right\n",
      "1.0 [0.7357048] right\n",
      "1.0 [0.02200401] wrong\n",
      "1.0 [0.999747] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.99950397] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.9997207] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.99999857] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.99993134] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.9998611] right\n",
      "1.0 [0.9932325] right\n",
      "1.0 [0.8044137] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.9983321] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.99912727] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.05712172] wrong\n",
      "1.0 [1.] right\n",
      "1.0 [2.2047673e-09] wrong\n",
      "1.0 [0.9997513] right\n",
      "1.0 [0.00721061] wrong\n",
      "1.0 [0.9999993] right\n",
      "1.0 [0.998664] right\n",
      "1.0 [0.99868023] right\n",
      "1.0 [1.9975253e-07] wrong\n",
      "1.0 [2.1316457e-09] wrong\n",
      "1.0 [0.996405] right\n",
      "1.0 [0.99999434] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.00684601] wrong\n",
      "1.0 [0.994428] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.995726] right\n",
      "1.0 [0.9568181] right\n",
      "1.0 [0.97962236] right\n",
      "1.0 [0.9915125] right\n",
      "1.0 [0.99649465] right\n",
      "1.0 [0.99855816] right\n",
      "1.0 [0.00387529] wrong\n",
      "1.0 [0.9999995] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.09604016] wrong\n",
      "1.0 [0.9997144] right\n",
      "1.0 [0.999949] right\n",
      "1.0 [0.9644095] right\n",
      "1.0 [0.99977636] right\n",
      "1.0 [7.579845e-13] wrong\n",
      "1.0 [0.99999744] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.9997018] right\n",
      "1.0 [0.00617462] wrong\n",
      "1.0 [0.99945754] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.9999516] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.99999845] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.99992746] right\n",
      "1.0 [0.99962175] right\n",
      "1.0 [0.99687135] right\n",
      "1.0 [0.99795115] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.9544937] right\n",
      "1.0 [0.9999994] right\n",
      "1.0 [0.99792844] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.99855757] right\n",
      "1.0 [0.99999976] right\n",
      "1.0 [0.9999297] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.99997187] right\n",
      "1.0 [0.9811837] right\n",
      "1.0 [0.99999094] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.99701995] right\n",
      "1.0 [0.00881964] wrong\n",
      "1.0 [1.] right\n",
      "1.0 [0.9999724] right\n",
      "1.0 [0.9999895] right\n",
      "1.0 [0.40298808] wrong\n",
      "1.0 [1.] right\n",
      "1.0 [0.09604016] wrong\n",
      "1.0 [0.9266794] right\n",
      "1.0 [0.0024372] wrong\n",
      "1.0 [1.] right\n",
      "1.0 [0.99774] right\n",
      "1.0 [0.9999871] right\n",
      "1.0 [0.00225544] wrong\n",
      "1.0 [0.00170001] wrong\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.3449105e-19] wrong\n",
      "1.0 [0.999992] right\n",
      "1.0 [0.99720764] right\n",
      "1.0 [0.99993] right\n",
      "1.0 [0.99984145] right\n",
      "1.0 [0.99110353] right\n",
      "1.0 [1.1301132e-16] wrong\n",
      "1.0 [0.9999839] right\n",
      "1.0 [0.9979374] right\n",
      "1.0 [5.327476e-07] wrong\n",
      "1.0 [0.99999547] right\n",
      "1.0 [0.99346256] right\n",
      "1.0 [0.9993043] right\n",
      "1.0 [0.9629811] right\n",
      "1.0 [6.4008182e-12] wrong\n",
      "1.0 [0.9181464] right\n",
      "1.0 [0.95859575] right\n",
      "1.0 [0.9710111] right\n",
      "1.0 [0.99871886] right\n",
      "1.0 [0.99999326] right\n",
      "1.0 [0.99902767] right\n",
      "1.0 [0.999998] right\n",
      "1.0 [0.9999913] right\n",
      "1.0 [0.9999937] right\n",
      "1.0 [0.00754356] wrong\n",
      "1.0 [0.9995637] right\n",
      "1.0 [0.99999917] right\n",
      "1.0 [0.9999234] right\n",
      "1.0 [0.99998695] right\n",
      "1.0 [0.9999998] right\n",
      "1.0 [7.0496624e-23] wrong\n",
      "1.0 [0.99972224] right\n",
      "1.0 [0.9999988] right\n",
      "1.0 [0.9964043] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.00235322] wrong\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.9511357] right\n",
      "1.0 [0.99924606] right\n",
      "1.0 [0.9989939] right\n",
      "1.0 [0.999869] right\n",
      "1.0 [0.00206393] wrong\n",
      "1.0 [0.06221768] wrong\n",
      "1.0 [0.00142097] wrong\n",
      "1.0 [1.] right\n",
      "1.0 [0.88264346] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.9999976] right\n",
      "1.0 [1.6762822e-08] wrong\n",
      "1.0 [0.23121652] wrong\n",
      "1.0 [0.9999912] right\n",
      "1.0 [0.9855226] right\n",
      "1.0 [0.9999975] right\n",
      "1.0 [0.9986041] right\n",
      "1.0 [0.9992224] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.9852995] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.9999999] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.02535027] wrong\n",
      "1.0 [0.09248498] wrong\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.999994] right\n",
      "1.0 [1.] right\n",
      "1.0 [2.6253768e-24] wrong\n",
      "1.0 [1.] right\n",
      "1.0 [0.9959656] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.9992069] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.02140781] wrong\n",
      "1.0 [0.99957085] right\n",
      "1.0 [0.9994954] right\n",
      "1.0 [1.505851e-09] wrong\n",
      "1.0 [0.9993564] right\n",
      "1.0 [0.9908554] right\n",
      "1.0 [0.00463417] wrong\n",
      "1.0 [1.] right\n",
      "1.0 [0.80126894] right\n",
      "1.0 [0.9916783] right\n",
      "1.0 [0.9832828] right\n",
      "1.0 [1.] right\n",
      "1.0 [5.8522237e-06] wrong\n",
      "1.0 [0.99646795] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.9998143] right\n",
      "1.0 [0.99999154] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.99999964] right\n",
      "1.0 [0.9999502] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.01015604] wrong\n",
      "1.0 [0.99875116] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.9999858] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.99995196] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.99999976] right\n",
      "1.0 [0.01458919] wrong\n",
      "1.0 [0.01145297] wrong\n",
      "1.0 [0.04191244] wrong\n",
      "1.0 [1.] right\n",
      "1.0 [0.9205966] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.9977102] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.8826353] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.99978435] right\n",
      "1.0 [0.00034192] wrong\n",
      "1.0 [1.] right\n",
      "1.0 [0.99886745] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [2.3927154e-15] wrong\n",
      "1.0 [0.8920668] right\n",
      "1.0 [0.99999726] right\n",
      "1.0 [0.99837005] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [6.123682e-09] wrong\n",
      "1.0 [0.8989012] right\n",
      "1.0 [0.99706846] right\n",
      "1.0 [0.9999457] right\n",
      "1.0 [0.9999995] right\n",
      "1.0 [0.99477285] right\n",
      "1.0 [0.9989521] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.9999995] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.01395404] wrong\n",
      "1.0 [1.] right\n",
      "1.0 [0.99654126] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.76933163] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.9999653] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.66313285] right\n",
      "1.0 [0.92189455] right\n",
      "1.0 [0.9999908] right\n",
      "1.0 [0.9961889] right\n",
      "1.0 [0.9999994] right\n",
      "1.0 [0.3645277] wrong\n",
      "1.0 [1.] right\n",
      "1.0 [0.99999976] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [8.0889674e-07] wrong\n",
      "1.0 [0.02488926] wrong\n",
      "1.0 [1.] right\n",
      "1.0 [0.99968576] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.9999995] right\n",
      "1.0 [0.96594715] right\n",
      "1.0 [0.00031272] wrong\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.9999533] right\n",
      "1.0 [0.7882011] right\n",
      "1.0 [0.15037072] wrong\n",
      "1.0 [0.9954537] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.00707731] wrong\n",
      "1.0 [0.9974523] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.99998236] right\n",
      "1.0 [0.9991852] right\n",
      "1.0 [0.9958954] right\n",
      "1.0 [0.99793637] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.99703777] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.9996385] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [1.] right\n",
      "1.0 [0.99803436] right\n",
      "1.0 [0.98902464] right\n",
      "1.0 [0.02068433] wrong\n",
      "1.0 [0.5181676] right\n",
      "1.0 [0.9999765] right\n",
      "1.0 [0.9999726] right\n",
      "1.0 [0.99995553] right\n",
      "1.0 [0.99999475] right\n",
      "1.0 [0.999808] right\n",
      "1.0 [0.33291936] wrong\n",
      "433 59\n"
     ]
    }
   ],
   "source": [
    "r_count = 0\n",
    "w_count = 0\n",
    "for index, i in enumerate(Y):\n",
    "    if i == 1.0:\n",
    "        if (predict[index] > 0.5):\n",
    "            r_count += 1\n",
    "            print(i, predict[index], 'right')\n",
    "        else :\n",
    "            w_count += 1\n",
    "            print(i, predict[index], 'wrong')\n",
    "print(r_count, w_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9999c952",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler= MinMaxScaler()\n",
    "df['Amount'] = scaler.fit_transform(df['Amount'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46afbbcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0.005824</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0.014739</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.004807</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0.002724</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>0.000965</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>0.002642</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>0.008446</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28    Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  0.005824   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724  0.000105   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  0.014739   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  0.004807   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153  0.002724   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731  0.000030   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527  0.000965   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561  0.002642   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533  0.000389   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  0.008446   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924edcc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17260f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CSV 데이터 종속, 독립 변수 분할\n",
    "dataset = df.values\n",
    "X = dataset[:,1:30]\n",
    "\n",
    "Y = dataset[:,30]       #종속변수\n",
    "#훈련, 테스트 데이터 분할\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.15, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d54152f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 구조 생성\n",
    "model = Sequential()\n",
    "model.add(Dense(30,  input_dim=29, activation='relu'))\n",
    "model.add(Dense(15, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d4bdf5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1937/1937 [==============================] - 4s 2ms/step - loss: 0.1122 - accuracy: 0.9404 - val_loss: 0.0044 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00444, saving model to ./model\\01-0.0044.hdf5\n",
      "Epoch 2/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.0041 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00444 to 0.00415, saving model to ./model\\02-0.0041.hdf5\n",
      "Epoch 3/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0040 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00415 to 0.00399, saving model to ./model\\03-0.0040.hdf5\n",
      "Epoch 4/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00399\n",
      "Epoch 5/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0038 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00399 to 0.00383, saving model to ./model\\05-0.0038.hdf5\n",
      "Epoch 6/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.0038 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00383\n",
      "Epoch 7/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.0037 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00383 to 0.00370, saving model to ./model\\07-0.0037.hdf5\n",
      "Epoch 8/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.0040 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00370\n",
      "Epoch 9/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0041 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00370\n",
      "Epoch 10/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0041 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00370\n",
      "Epoch 11/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0041 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00370\n",
      "Epoch 12/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0048 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.00370\n",
      "Epoch 13/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0041 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.00370\n",
      "Epoch 14/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0041 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.00370\n",
      "Epoch 15/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0045 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.00370\n",
      "Epoch 16/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0053 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.00370\n",
      "Epoch 17/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0046 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.00370\n",
      "Epoch 18/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0058 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.00370\n",
      "Epoch 19/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0104 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.00370\n",
      "Epoch 20/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0048 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.00370\n",
      "Epoch 21/200\n",
      "1937/1937 [==============================] - 3s 1ms/step - loss: 8.7795e-04 - accuracy: 0.9997 - val_loss: 0.0087 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.00370\n",
      "Epoch 22/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 8.7060e-04 - accuracy: 0.9997 - val_loss: 0.0054 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.00370\n",
      "Epoch 23/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 9.7970e-04 - accuracy: 0.9996 - val_loss: 0.0053 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.00370\n",
      "Epoch 24/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 7.8848e-04 - accuracy: 0.9997 - val_loss: 0.0057 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.00370\n",
      "Epoch 25/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 8.8241e-04 - accuracy: 0.9997 - val_loss: 0.0073 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.00370\n",
      "Epoch 26/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 8.3358e-04 - accuracy: 0.9997 - val_loss: 0.0057 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.00370\n",
      "Epoch 27/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 6.4900e-04 - accuracy: 0.9998 - val_loss: 0.0062 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.00370\n",
      "Epoch 28/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 7.9599e-04 - accuracy: 0.9997 - val_loss: 0.0067 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.00370\n",
      "Epoch 29/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 7.1260e-04 - accuracy: 0.9998 - val_loss: 0.0083 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.00370\n",
      "Epoch 30/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0075 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.00370\n",
      "Epoch 31/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 6.5414e-04 - accuracy: 0.9998 - val_loss: 0.0084 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.00370\n",
      "Epoch 32/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 7.6881e-04 - accuracy: 0.9998 - val_loss: 0.0074 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.00370\n",
      "Epoch 33/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 8.1916e-04 - accuracy: 0.9998 - val_loss: 0.0075 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.00370\n",
      "Epoch 34/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 6.5486e-04 - accuracy: 0.9997 - val_loss: 0.0073 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.00370\n",
      "Epoch 35/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 5.8975e-04 - accuracy: 0.9997 - val_loss: 0.0094 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.00370\n",
      "Epoch 36/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 7.6239e-04 - accuracy: 0.9997 - val_loss: 0.0087 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.00370\n",
      "Epoch 37/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 4.9317e-04 - accuracy: 0.9998 - val_loss: 0.0092 - val_accuracy: 0.9991\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.00370\n",
      "Epoch 38/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 6.1412e-04 - accuracy: 0.9997 - val_loss: 0.0099 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.00370\n",
      "Epoch 39/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 5.1929e-04 - accuracy: 0.9998 - val_loss: 0.0088 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.00370\n",
      "Epoch 40/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 5.3361e-04 - accuracy: 0.9998 - val_loss: 0.0096 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.00370\n",
      "Epoch 41/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1937/1937 [==============================] - 3s 2ms/step - loss: 5.7776e-04 - accuracy: 0.9998 - val_loss: 0.0087 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.00370\n",
      "Epoch 42/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 6.2028e-04 - accuracy: 0.9998 - val_loss: 0.0089 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.00370\n",
      "Epoch 43/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 3.1158e-04 - accuracy: 0.9999 - val_loss: 0.0122 - val_accuracy: 0.9988\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.00370\n",
      "Epoch 44/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0103 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.00370\n",
      "Epoch 45/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 6.5625e-04 - accuracy: 0.9997 - val_loss: 0.0093 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.00370\n",
      "Epoch 46/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 4.9629e-04 - accuracy: 0.9998 - val_loss: 0.0103 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.00370\n",
      "Epoch 47/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 4.9171e-04 - accuracy: 0.9998 - val_loss: 0.0095 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.00370\n",
      "Epoch 48/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 3.9653e-04 - accuracy: 0.9999 - val_loss: 0.0113 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.00370\n",
      "Epoch 49/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 6.1168e-04 - accuracy: 0.9997 - val_loss: 0.0109 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.00370\n",
      "Epoch 50/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 4.9753e-04 - accuracy: 0.9998 - val_loss: 0.0105 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.00370\n",
      "Epoch 51/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 4.5748e-04 - accuracy: 0.9998 - val_loss: 0.0108 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.00370\n",
      "Epoch 52/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 3.1370e-04 - accuracy: 0.9999 - val_loss: 0.0102 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.00370\n",
      "Epoch 53/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 4.5250e-04 - accuracy: 0.9998 - val_loss: 0.0116 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.00370\n",
      "Epoch 54/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 5.0852e-04 - accuracy: 0.9998 - val_loss: 0.0117 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.00370\n",
      "Epoch 55/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 4.0712e-04 - accuracy: 0.9999 - val_loss: 0.0184 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.00370\n",
      "Epoch 56/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 6.0533e-04 - accuracy: 0.9999 - val_loss: 0.0108 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.00370\n",
      "Epoch 57/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 4.3938e-04 - accuracy: 0.9999 - val_loss: 0.0142 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.00370\n",
      "Epoch 58/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 4.4726e-04 - accuracy: 0.9999 - val_loss: 0.0113 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.00370\n",
      "Epoch 59/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 3.9686e-04 - accuracy: 0.9998 - val_loss: 0.0144 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.00370\n",
      "Epoch 60/200\n",
      "1937/1937 [==============================] - 3s 1ms/step - loss: 5.0660e-04 - accuracy: 0.9998 - val_loss: 0.0119 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.00370\n",
      "Epoch 61/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 4.1503e-04 - accuracy: 0.9999 - val_loss: 0.0131 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.00370\n",
      "Epoch 62/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 3.2632e-04 - accuracy: 0.9999 - val_loss: 0.0135 - val_accuracy: 0.99947e-04 - \n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.00370\n",
      "Epoch 63/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 4.1977e-04 - accuracy: 0.9999 - val_loss: 0.0123 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.00370\n",
      "Epoch 64/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 6.1129e-04 - accuracy: 0.9998 - val_loss: 0.0125 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.00370\n",
      "Epoch 65/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 2.9467e-04 - accuracy: 0.9999 - val_loss: 0.0143 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.00370\n",
      "Epoch 66/200\n",
      "1937/1937 [==============================] - 3s 1ms/step - loss: 4.9599e-04 - accuracy: 0.9998 - val_loss: 0.0127 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.00370\n",
      "Epoch 67/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 4.2321e-04 - accuracy: 0.9999 - val_loss: 0.0132 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.00370\n",
      "Epoch 68/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 3.4011e-04 - accuracy: 0.9999 - val_loss: 0.0137 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.00370\n",
      "Epoch 69/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 2.4765e-04 - accuracy: 0.9999 - val_loss: 0.0136 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.00370\n",
      "Epoch 70/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 4.6837e-04 - accuracy: 0.9999 - val_loss: 0.0140 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.00370\n",
      "Epoch 71/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 3.5588e-04 - accuracy: 0.9999 - val_loss: 0.0183 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.00370\n",
      "Epoch 72/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 4.3553e-04 - accuracy: 0.9999 - val_loss: 0.0148 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.00370\n",
      "Epoch 73/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 3.2633e-04 - accuracy: 0.9998 - val_loss: 0.0148 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.00370\n",
      "Epoch 74/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 5.4639e-04 - accuracy: 0.9998 - val_loss: 0.0154 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.00370\n",
      "Epoch 75/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 4.5764e-04 - accuracy: 0.9998 - val_loss: 0.0129 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.00370\n",
      "Epoch 76/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 3.3675e-04 - accuracy: 0.9999 - val_loss: 0.0127 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.00370\n",
      "Epoch 77/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 2.8045e-04 - accuracy: 0.9999 - val_loss: 0.0126 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.00370\n",
      "Epoch 78/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 3.7730e-04 - accuracy: 0.9999 - val_loss: 0.0147 - val_accuracy: 0.9990\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.00370\n",
      "Epoch 79/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 5.6919e-04 - accuracy: 0.9998 - val_loss: 0.0127 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.00370\n",
      "Epoch 80/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 6.1251e-04 - accuracy: 0.9998 - val_loss: 0.0132 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.00370\n",
      "Epoch 81/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 3.9711e-04 - accuracy: 0.9999 - val_loss: 0.0178 - val_accuracy: 0.9993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00081: val_loss did not improve from 0.00370\n",
      "Epoch 82/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 5.7782e-04 - accuracy: 0.9999 - val_loss: 0.0138 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.00370\n",
      "Epoch 83/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 3.3274e-04 - accuracy: 0.9999 - val_loss: 0.0172 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.00370\n",
      "Epoch 84/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 3.7159e-04 - accuracy: 0.9999 - val_loss: 0.0129 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.00370\n",
      "Epoch 85/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 2.2227e-04 - accuracy: 0.9999 - val_loss: 0.0135 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.00370\n",
      "Epoch 86/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0135 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.00370\n",
      "Epoch 87/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 4.0657e-04 - accuracy: 0.9998 - val_loss: 0.0134 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.00370\n",
      "Epoch 88/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 3.9289e-04 - accuracy: 0.9999 - val_loss: 0.0146 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.00370\n",
      "Epoch 89/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 3.3062e-04 - accuracy: 0.9999 - val_loss: 0.0147 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.00370\n",
      "Epoch 90/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 3.0311e-04 - accuracy: 0.9999 - val_loss: 0.0164 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.00370\n",
      "Epoch 91/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 3.5423e-04 - accuracy: 0.9999 - val_loss: 0.0156 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.00370\n",
      "Epoch 92/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 3.1320e-04 - accuracy: 0.9999 - val_loss: 0.0154 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.00370\n",
      "Epoch 93/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 2.9559e-04 - accuracy: 0.9999 - val_loss: 0.0150 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.00370\n",
      "Epoch 94/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 3.9399e-04 - accuracy: 0.9999 - val_loss: 0.0177 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.00370\n",
      "Epoch 95/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 3.6987e-04 - accuracy: 0.9999 - val_loss: 0.0140 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.00370\n",
      "Epoch 96/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 2.4581e-04 - accuracy: 0.9999 - val_loss: 0.0147 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.00370\n",
      "Epoch 97/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 2.3319e-04 - accuracy: 0.9999 - val_loss: 0.0154 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.00370\n",
      "Epoch 98/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 2.6697e-04 - accuracy: 0.9999 - val_loss: 0.0155 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.00370\n",
      "Epoch 99/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 3.7268e-04 - accuracy: 0.9999 - val_loss: 0.0176 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.00370\n",
      "Epoch 100/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 4.6286e-04 - accuracy: 0.9999 - val_loss: 0.0204 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.00370\n",
      "Epoch 101/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 3.4752e-04 - accuracy: 0.9999 - val_loss: 0.0150 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.00370\n",
      "Epoch 102/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 2.6640e-04 - accuracy: 0.9999 - val_loss: 0.0170 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.00370\n",
      "Epoch 103/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 4.7542e-04 - accuracy: 0.9999 - val_loss: 0.0169 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.00370\n",
      "Epoch 104/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 1.8635e-04 - accuracy: 0.9999 - val_loss: 0.0141 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.00370\n",
      "Epoch 105/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 9.1632e-04 - accuracy: 0.9999 - val_loss: 0.0138 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.00370\n",
      "Epoch 106/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 1.4926e-04 - accuracy: 1.0000 - val_loss: 0.0178 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.00370\n",
      "Epoch 107/200\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 4.6918e-04 - accuracy: 0.9998 - val_loss: 0.0163 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.00370\n"
     ]
    }
   ],
   "source": [
    "#모델 컴파일 및 학습\n",
    "model.compile(loss='binary_crossentropy',\n",
    "          optimizer='adam',\n",
    "          metrics=['accuracy'])\n",
    "MODEL_DIR = './credit_model/'\n",
    "\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "    \n",
    "modelpath = './model/{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "checkpointer = ModelCheckpoint(filepath = modelpath, monitor = 'val_loss', verbose = 1, save_best_only=True)\n",
    "\n",
    "early_stopping_callback= EarlyStopping(monitor= 'val_loss', patience = 100)\n",
    "\n",
    "history = model.fit(X_train, Y_train, validation_split=0.2, epochs=200, batch_size=100, callbacks = [early_stopping_callback,checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9b87220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1336/1336 [==============================] - 1s 883us/step - loss: 0.0100 - accuracy: 0.9994\n",
      "[0.010041842237114906, 0.9994382262229919]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b64f410",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5daf8566",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0000000000 0.0\n",
      "0.0000000000 0.0\n",
      "0.0000000000 0.0\n",
      "0.0000000000 0.0\n",
      "0.0000000000 0.0\n",
      "0.0000000000 0.0\n",
      "0.0000002350 0.0\n",
      "0.0000000000 0.0\n",
      "0.0000000000 0.0\n",
      "0.0000000000 0.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print('%.10f' % predict[i], Y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c087cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(Y[541])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf8e9081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73685086] 0.0 wrong\n",
      "[0.99999696] 1.0 right\n",
      "[0.99932885] 1.0 right\n",
      "[0.9999976] 1.0 right\n",
      "[0.74550545] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9999995] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.99999875] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 0.0 wrong\n",
      "[0.99432516] 1.0 right\n",
      "[0.99908245] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 0.0 wrong\n",
      "[1.] 1.0 right\n",
      "[0.999994] 0.0 wrong\n",
      "[1.] 1.0 right\n",
      "[0.99001265] 0.0 wrong\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.7454646] 0.0 wrong\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9999992] 1.0 right\n",
      "[0.874037] 1.0 right\n",
      "[0.88851535] 1.0 right\n",
      "[0.8838951] 1.0 right\n",
      "[0.87911546] 1.0 right\n",
      "[0.87417203] 1.0 right\n",
      "[0.98963404] 1.0 right\n",
      "[0.98700345] 1.0 right\n",
      "[0.9837173] 1.0 right\n",
      "[0.9796185] 1.0 right\n",
      "[0.9745158] 1.0 right\n",
      "[0.9681785] 1.0 right\n",
      "[0.9603311] 1.0 right\n",
      "[0.94527817] 0.0 wrong\n",
      "[1.] 1.0 right\n",
      "[0.9130324] 1.0 right\n",
      "[0.9999987] 0.0 wrong\n",
      "[0.99986666] 1.0 right\n",
      "[0.90686536] 1.0 right\n",
      "[0.9998621] 0.0 wrong\n",
      "[0.87411815] 1.0 right\n",
      "[0.83005345] 1.0 right\n",
      "[0.7505698] 1.0 right\n",
      "[0.6275507] 1.0 right\n",
      "[0.9956622] 0.0 wrong\n",
      "[0.9348109] 0.0 wrong\n",
      "[0.5266816] 0.0 wrong\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9988] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.99999255] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9999995] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.64566636] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.99995446] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9999977] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9999967] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9999995] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.94071954] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.999995] 1.0 right\n",
      "[0.9999365] 1.0 right\n",
      "[0.9849287] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9224268] 1.0 right\n",
      "[0.9999942] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.5278161] 1.0 right\n",
      "[0.8272301] 1.0 right\n",
      "[0.8339335] 1.0 right\n",
      "[0.8625239] 1.0 right\n",
      "[0.9805212] 1.0 right\n",
      "[0.9103395] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9999998] 1.0 right\n",
      "[0.99999785] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9173955] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.56508696] 1.0 right\n",
      "[0.99999] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9993384] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9999976] 1.0 right\n",
      "[0.999893] 1.0 right\n",
      "[0.9659791] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.96697986] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.99822223] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.84518766] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.81284726] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.99999964] 1.0 right\n",
      "[0.95991796] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9862048] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.999999] 1.0 right\n",
      "[0.9001244] 0.0 wrong\n",
      "[0.99999607] 1.0 right\n",
      "[0.9999969] 1.0 right\n",
      "[0.99999976] 0.0 wrong\n",
      "[0.97847104] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 0.0 wrong\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.82785535] 1.0 right\n",
      "[0.99008167] 1.0 right\n",
      "[0.69533926] 1.0 right\n",
      "[0.8917477] 1.0 right\n",
      "[0.99999607] 1.0 right\n",
      "[0.52373224] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.99961746] 1.0 right\n",
      "[0.99914527] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9897187] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.99999976] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.97652817] 1.0 right\n",
      "[0.8055208] 0.0 wrong\n",
      "[1.] 1.0 right\n",
      "[0.8961284] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9999996] 0.0 wrong\n",
      "[0.8062985] 0.0 wrong\n",
      "[0.8062985] 0.0 wrong\n",
      "[0.91076124] 1.0 right\n",
      "[0.9999998] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.99996907] 1.0 right\n",
      "[0.9474511] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9999572] 0.0 wrong\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.99917716] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.7749796] 0.0 wrong\n",
      "[0.9999837] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.8771488] 0.0 wrong\n",
      "[0.99923944] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.8683131] 1.0 right\n",
      "[0.99397576] 0.0 wrong\n",
      "[0.9995322] 0.0 wrong\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.99999976] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.99999976] 1.0 right\n",
      "[0.6092664] 0.0 wrong\n",
      "[0.6899906] 1.0 right\n",
      "[0.99999464] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 0.0 wrong\n",
      "[0.53408706] 0.0 wrong\n",
      "[1.] 1.0 right\n",
      "[0.9996383] 1.0 right\n",
      "[0.9976645] 1.0 right\n",
      "[0.99999046] 0.0 wrong\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9586595] 1.0 right\n",
      "[0.7246088] 1.0 right\n",
      "[0.98814714] 1.0 right\n",
      "[0.9999998] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9998869] 1.0 right\n",
      "[0.6039138] 0.0 wrong\n",
      "[0.9999996] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9914994] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9997405] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9959539] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.77704585] 0.0 wrong\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9999932] 1.0 right\n",
      "[0.9999956] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9999974] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9930328] 0.0 wrong\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.902875] 1.0 right\n",
      "[0.99999905] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.999673] 1.0 right\n",
      "[0.99999547] 1.0 right\n",
      "[0.99999964] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9503786] 1.0 right\n",
      "[0.96932626] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.99998546] 1.0 right\n",
      "[0.943943] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9999975] 1.0 right\n",
      "[0.9999981] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.5321587] 0.0 wrong\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.99852073] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9999987] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9994289] 0.0 wrong\n",
      "[0.98814064] 1.0 right\n",
      "[0.81979215] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9999995] 1.0 right\n",
      "[0.9981178] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[1.] 1.0 right\n",
      "[0.9999819] 0.0 wrong\n",
      "440 34\n"
     ]
    }
   ],
   "source": [
    "r_count = 0\n",
    "w_count = 0\n",
    "for index, i in enumerate(predict):\n",
    "    if i > 0.5:\n",
    "        if (Y[index] == 1.0):\n",
    "            r_count += 1\n",
    "            print(i, Y[index], 'right')\n",
    "        else :\n",
    "            w_count += 1\n",
    "            print(i, Y[index], 'wrong')\n",
    "print(r_count, w_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02eeef3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440 52 474 284333\n"
     ]
    }
   ],
   "source": [
    "r_count = 0\n",
    "w_count = 0\n",
    "pred_r = 0\n",
    "pred_w = 0\n",
    "for index, i in enumerate(Y):\n",
    "    if i == 1.0:\n",
    "        if (predict[index] > 0.5):\n",
    "            r_count += 1\n",
    "        else :\n",
    "            w_count += 1\n",
    "    if predict[index] > 0.5:\n",
    "        pred_r += 1\n",
    "    else:\n",
    "        pred_w += 1\n",
    "print(r_count, w_count, pred_r, pred_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "202af861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_vloss = history.history['val_loss']\n",
    "y_acc = history.history['accuracy']\n",
    "x_len = numpy.arange(len(y_vloss))\n",
    "plt.plot(x_len, y_vloss, 'o', c='red', markersize=3)\n",
    "plt.plot(x_len, y_acc, 'o', c='blue', markersize=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef75b86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
