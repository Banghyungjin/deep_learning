{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "707eaf47",
   "metadata": {},
   "source": [
    "## import할 모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90f6c8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*- coding: utf-8 -*-\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score,confusion_matrix, precision_recall_curve\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import numpy\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import graphviz\n",
    "import time\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aad95de",
   "metadata": {},
   "source": [
    "## CSV 파일 읽어오기, seed 값 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53adfa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 값 설정\n",
    "seed = 0\n",
    "numpy.random.seed(seed)\n",
    "tf.random.set_seed(3)\n",
    "df = pd.read_csv(\"creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b3bf3b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "407bc471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 세트 Null 값 갯수 \n",
      " Time      0\n",
      "V1        0\n",
      "V2        0\n",
      "V3        0\n",
      "V4        0\n",
      "V5        0\n",
      "V6        0\n",
      "V7        0\n",
      "V8        0\n",
      "V9        0\n",
      "V10       0\n",
      "V11       0\n",
      "V12       0\n",
      "V13       0\n",
      "V14       0\n",
      "V15       0\n",
      "V16       0\n",
      "V17       0\n",
      "V18       0\n",
      "V19       0\n",
      "V20       0\n",
      "V21       0\n",
      "V22       0\n",
      "V23       0\n",
      "V24       0\n",
      "V25       0\n",
      "V26       0\n",
      "V27       0\n",
      "V28       0\n",
      "Amount    0\n",
      "Class     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('데이터 세트 Null 값 갯수 \\n',df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2578a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CSV 데이터 종속, 독립 변수 분할\n",
    "dataset = df.values\n",
    "X = dataset[:,1:30]\n",
    "\n",
    "Y = dataset[:,30]       #종속변수\n",
    "#훈련, 테스트 데이터 분할\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.15, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b02e33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 구조 생성\n",
    "model = Sequential()\n",
    "model.add(Dense(30,  input_dim=29, activation='relu'))\n",
    "model.add(Dense(15, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac83f397",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1937/1937 [==============================] - 5s 2ms/step - loss: 0.0652 - accuracy: 0.9895 - val_loss: 0.0253 - val_accuracy: 0.9987\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02526, saving model to ./model\\01-0.0253.hdf5\n",
      "Epoch 2/100\n",
      "1937/1937 [==============================] - 3s 1ms/step - loss: 0.0084 - accuracy: 0.9994 - val_loss: 0.0078 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02526 to 0.00775, saving model to ./model\\02-0.0078.hdf5\n",
      "Epoch 3/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0079 - accuracy: 0.9993 - val_loss: 0.0077 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00775 to 0.00769, saving model to ./model\\03-0.0077.hdf5\n",
      "Epoch 4/100\n",
      "1937/1937 [==============================] - 3s 1ms/step - loss: 0.0049 - accuracy: 0.9994 - val_loss: 0.0065 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00769 to 0.00651, saving model to ./model\\04-0.0065.hdf5\n",
      "Epoch 5/100\n",
      "1937/1937 [==============================] - 3s 1ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.0278 - val_accuracy: 0.9987\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00651\n",
      "Epoch 6/100\n",
      "1937/1937 [==============================] - 3s 1ms/step - loss: 0.0082 - accuracy: 0.9993 - val_loss: 0.0057 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00651 to 0.00565, saving model to ./model\\06-0.0057.hdf5\n",
      "Epoch 7/100\n",
      "1937/1937 [==============================] - 3s 1ms/step - loss: 0.0044 - accuracy: 0.9994 - val_loss: 0.0053 - val_accuracy: 0.9991\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00565 to 0.00531, saving model to ./model\\07-0.0053.hdf5\n",
      "Epoch 8/100\n",
      "1937/1937 [==============================] - 3s 1ms/step - loss: 0.0048 - accuracy: 0.9994 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00531 to 0.00463, saving model to ./model\\08-0.0046.hdf5\n",
      "Epoch 9/100\n",
      "1937/1937 [==============================] - 3s 1ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.0104 - val_accuracy: 0.9986\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00463\n",
      "Epoch 10/100\n",
      "1937/1937 [==============================] - 3s 1ms/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 0.0053 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00463\n",
      "Epoch 11/100\n",
      "1937/1937 [==============================] - 3s 1ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.0048 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00463\n",
      "Epoch 12/100\n",
      "1937/1937 [==============================] - 3s 1ms/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 0.0048 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.00463\n",
      "Epoch 13/100\n",
      "1937/1937 [==============================] - 3s 1ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.0052 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.00463\n",
      "Epoch 14/100\n",
      "1937/1937 [==============================] - 3s 1ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.0044 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.00463 to 0.00444, saving model to ./model\\14-0.0044.hdf5\n",
      "Epoch 15/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.0040 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.00444 to 0.00399, saving model to ./model\\15-0.0040.hdf5\n",
      "Epoch 16/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 0.0042 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.00399\n",
      "Epoch 17/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0023 - accuracy: 0.9997 - val_loss: 0.0037 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.00399 to 0.00375, saving model to ./model\\17-0.0037.hdf5\n",
      "Epoch 18/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.0044 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.00375\n",
      "Epoch 19/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.0044 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.00375\n",
      "Epoch 20/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.0046 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.00375\n",
      "Epoch 21/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.0044 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.00375\n",
      "Epoch 22/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.0038 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.00375\n",
      "Epoch 23/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.0048 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.00375\n",
      "Epoch 24/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.0042 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.00375\n",
      "Epoch 25/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.0043 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.00375\n",
      "Epoch 26/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.0047 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.00375\n",
      "Epoch 27/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.0059 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.00375\n",
      "Epoch 28/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0041 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.00375\n",
      "Epoch 29/100\n",
      "1937/1937 [==============================] - 3s 1ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.0042 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.00375\n",
      "Epoch 30/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.0056 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.00375\n",
      "Epoch 31/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.0062 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.00375\n",
      "Epoch 32/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0041 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.00375\n",
      "Epoch 33/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0046 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.00375\n",
      "Epoch 34/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0041 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.00375\n",
      "Epoch 35/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0059 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.00375\n",
      "Epoch 36/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0045 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.00375\n",
      "Epoch 37/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.0046 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.00375\n",
      "Epoch 38/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.0042 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.00375\n",
      "Epoch 39/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0041 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.00375\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0056 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.00375\n",
      "Epoch 41/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0045 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.00375\n",
      "Epoch 42/100\n",
      "1937/1937 [==============================] - 4s 2ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0045 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.00375\n",
      "Epoch 43/100\n",
      "1937/1937 [==============================] - 5s 2ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0051 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.00375\n",
      "Epoch 44/100\n",
      "1937/1937 [==============================] - 4s 2ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0049 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.00375\n",
      "Epoch 45/100\n",
      "1937/1937 [==============================] - 4s 2ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0056 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.00375\n",
      "Epoch 46/100\n",
      "1937/1937 [==============================] - 4s 2ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0043 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.00375\n",
      "Epoch 47/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0046 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.00375\n"
     ]
    }
   ],
   "source": [
    "#모델 컴파일 및 학습\n",
    "model.compile(loss='binary_crossentropy',\n",
    "          optimizer='adam',\n",
    "          metrics=['accuracy'])\n",
    "MODEL_DIR = './credit_model/'\n",
    "\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "    \n",
    "modelpath = './model/{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "checkpointer = ModelCheckpoint(filepath = modelpath, monitor = 'val_loss', verbose = 1, save_best_only=True)\n",
    "\n",
    "early_stopping_callback= EarlyStopping(monitor= 'val_loss', patience = 20)\n",
    "\n",
    "history = model.fit(X_train, Y_train, validation_split=0.2, epochs=100, batch_size=100, callbacks = [early_stopping_callback,checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32212f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1336/1336 [==============================] - 1s 976us/step - loss: 0.0046 - accuracy: 0.9995\n",
      "[0.004616077058017254, 0.9995318651199341]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6331743f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eee4a87d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0010518730 0.0\n",
      "0.0000003798 0.0\n",
      "0.0012213588 0.0\n",
      "0.0000000482 0.0\n",
      "0.0000290635 0.0\n",
      "0.0000014384 0.0\n",
      "0.0000010678 0.0\n",
      "0.0000000913 0.0\n",
      "0.0000000067 0.0\n",
      "0.0000004149 0.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print('%.10f' % predict[i], Y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfb96f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418 18 284297 74\n"
     ]
    }
   ],
   "source": [
    "r_count = 0\n",
    "w_count = 0\n",
    "pred_r = 0\n",
    "pred_w = 0\n",
    "tp = 0\n",
    "fp = 0\n",
    "tn = 0\n",
    "fn = 0\n",
    "for index, i in enumerate(Y):\n",
    "    if i == 1.0:\n",
    "        if (predict[index] > 0.5):\n",
    "            tp += 1\n",
    "        else :\n",
    "            fn += 1\n",
    "    else:\n",
    "        if (predict[index] > 0.5):\n",
    "            fp += 1\n",
    "        else :\n",
    "            tn += 1\n",
    "print(tp, fp, tn, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bac73a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision =\t 0.9587155963302753\n",
      "recall =\t 0.8495934959349594\n"
     ]
    }
   ],
   "source": [
    "print(\"precision =\\t\", tp / (tp + fp))\n",
    "print(\"recall =\\t\", tp / (tp + fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22793568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_vloss = history.history['val_loss']\n",
    "y_acc = history.history['accuracy']\n",
    "x_len = numpy.arange(len(y_vloss))\n",
    "plt.plot(x_len, y_vloss, 'o', c='red', markersize=3)\n",
    "plt.plot(x_len, y_acc, 'o', c='blue', markersize=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f0841fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler= MinMaxScaler()\n",
    "df['Amount'] = scaler.fit_transform(df['Amount'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f33d9e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0.005824</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0.014739</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.004807</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0.002724</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>0.000965</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>0.002642</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>0.008446</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28    Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  0.005824   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724  0.000105   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  0.014739   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  0.004807   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153  0.002724   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731  0.000030   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527  0.000965   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561  0.002642   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533  0.000389   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  0.008446   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a45f0e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CSV 데이터 종속, 독립 변수 분할\n",
    "dataset = df.values\n",
    "X = dataset[:,1:30]\n",
    "\n",
    "Y = dataset[:,30]       #종속변수\n",
    "#훈련, 테스트 데이터 분할\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.15, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b94ba44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1937/1937 [==============================] - 4s 2ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 0.0038 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00383, saving model to ./model\\01-0.0038.hdf5\n",
      "Epoch 2/100\n",
      "1937/1937 [==============================] - 3s 1ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0037 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00383 to 0.00366, saving model to ./model\\02-0.0037.hdf5\n",
      "Epoch 3/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0039 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.00366\n",
      "Epoch 4/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0044 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00366\n",
      "Epoch 5/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0040 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00366\n",
      "Epoch 6/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0051 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00366\n",
      "Epoch 7/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0043 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00366\n",
      "Epoch 8/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0056 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00366\n",
      "Epoch 9/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 9.3986e-04 - accuracy: 0.9998 - val_loss: 0.0054 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00366\n",
      "Epoch 10/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 9.6779e-04 - accuracy: 0.9997 - val_loss: 0.0053 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00366\n",
      "Epoch 11/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 9.7812e-04 - accuracy: 0.9998 - val_loss: 0.0059 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00366\n",
      "Epoch 12/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 9.3545e-04 - accuracy: 0.9998 - val_loss: 0.0062 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.00366\n",
      "Epoch 13/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0064 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.00366\n",
      "Epoch 14/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.0065 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.00366\n",
      "Epoch 15/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0070 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.00366\n",
      "Epoch 16/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0081 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.00366\n",
      "Epoch 17/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0076 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.00366\n",
      "Epoch 18/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0077 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.00366\n",
      "Epoch 19/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0103 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.00366\n",
      "Epoch 20/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.0092 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.00366\n",
      "Epoch 21/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 9.6541e-04 - accuracy: 0.9997 - val_loss: 0.0085 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.00366\n",
      "Epoch 22/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 5.9730e-04 - accuracy: 0.9998 - val_loss: 0.0080 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.00366\n"
     ]
    }
   ],
   "source": [
    "#모델 컴파일 및 학습\n",
    "model.compile(loss='binary_crossentropy',\n",
    "          optimizer='adam',\n",
    "          metrics=['accuracy'])\n",
    "MODEL_DIR = './credit_model/'\n",
    "\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "    \n",
    "modelpath = './model/{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "checkpointer = ModelCheckpoint(filepath = modelpath, monitor = 'val_loss', verbose = 1, save_best_only=True)\n",
    "\n",
    "early_stopping_callback= EarlyStopping(monitor= 'val_loss', patience = 20)\n",
    "\n",
    "history = model.fit(X_train, Y_train, validation_split=0.2, epochs=100, batch_size=100, callbacks = [early_stopping_callback,checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89caec90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1336/1336 [==============================] - 1s 977us/step - loss: 0.0064 - accuracy: 0.9995\n",
      "[0.006423380225896835, 0.9994850158691406]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e76ca269",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb2fda98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0000007490 0.0\n",
      "0.0000000004 0.0\n",
      "0.0000000004 0.0\n",
      "0.0000008722 0.0\n",
      "0.0000003019 0.0\n",
      "0.0000178093 0.0\n",
      "0.0006220043 0.0\n",
      "0.0000000143 0.0\n",
      "0.0000000053 0.0\n",
      "0.0000127291 0.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print('%.10f' % predict[i], Y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d285a2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426 27 284288 66\n"
     ]
    }
   ],
   "source": [
    "r_count = 0\n",
    "w_count = 0\n",
    "pred_r = 0\n",
    "pred_w = 0\n",
    "tp = 0\n",
    "fp = 0\n",
    "tn = 0\n",
    "fn = 0\n",
    "for index, i in enumerate(Y):\n",
    "    if i == 1.0:\n",
    "        if (predict[index] > 0.5):\n",
    "            tp += 1\n",
    "        else :\n",
    "            fn += 1\n",
    "    else:\n",
    "        if (predict[index] > 0.5):\n",
    "            fp += 1\n",
    "        else :\n",
    "            tn += 1\n",
    "print(tp, fp, tn, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56d33980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision =\t 0.9403973509933775\n",
      "recall =\t 0.8658536585365854\n"
     ]
    }
   ],
   "source": [
    "print(\"precision =\\t\", tp / (tp + fp))\n",
    "print(\"recall =\\t\", tp / (tp + fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc81256e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_vloss = history.history['val_loss']\n",
    "y_acc = history.history['accuracy']\n",
    "x_len = numpy.arange(len(y_vloss))\n",
    "plt.plot(x_len, y_vloss, 'o', c='red', markersize=3)\n",
    "plt.plot(x_len, y_acc, 'o', c='blue', markersize=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9672c2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c95190ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>183484</th>\n",
       "      <td>125821.0</td>\n",
       "      <td>-0.323334</td>\n",
       "      <td>1.057455</td>\n",
       "      <td>-0.048341</td>\n",
       "      <td>-0.607204</td>\n",
       "      <td>1.259821</td>\n",
       "      <td>-0.091761</td>\n",
       "      <td>1.159101</td>\n",
       "      <td>-0.124335</td>\n",
       "      <td>-0.174640</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.207098</td>\n",
       "      <td>-0.433890</td>\n",
       "      <td>-0.261613</td>\n",
       "      <td>-0.046651</td>\n",
       "      <td>0.211512</td>\n",
       "      <td>0.008297</td>\n",
       "      <td>0.108494</td>\n",
       "      <td>0.161139</td>\n",
       "      <td>0.001557</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255448</th>\n",
       "      <td>157235.0</td>\n",
       "      <td>-0.349718</td>\n",
       "      <td>0.932619</td>\n",
       "      <td>0.142992</td>\n",
       "      <td>-0.657071</td>\n",
       "      <td>1.169784</td>\n",
       "      <td>-0.733369</td>\n",
       "      <td>1.009985</td>\n",
       "      <td>-0.071069</td>\n",
       "      <td>-0.302083</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.271537</td>\n",
       "      <td>-0.833209</td>\n",
       "      <td>-0.030360</td>\n",
       "      <td>0.490035</td>\n",
       "      <td>-0.404816</td>\n",
       "      <td>0.134350</td>\n",
       "      <td>0.076830</td>\n",
       "      <td>0.175562</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244749</th>\n",
       "      <td>152471.0</td>\n",
       "      <td>-1.614711</td>\n",
       "      <td>-2.406570</td>\n",
       "      <td>0.326194</td>\n",
       "      <td>0.665520</td>\n",
       "      <td>2.369268</td>\n",
       "      <td>-1.775367</td>\n",
       "      <td>-1.139049</td>\n",
       "      <td>0.329904</td>\n",
       "      <td>0.903813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.701399</td>\n",
       "      <td>1.134489</td>\n",
       "      <td>0.965054</td>\n",
       "      <td>0.640981</td>\n",
       "      <td>-1.801998</td>\n",
       "      <td>-1.041114</td>\n",
       "      <td>0.286285</td>\n",
       "      <td>0.437322</td>\n",
       "      <td>0.003737</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63919</th>\n",
       "      <td>50927.0</td>\n",
       "      <td>-2.477184</td>\n",
       "      <td>0.860613</td>\n",
       "      <td>1.441850</td>\n",
       "      <td>1.051019</td>\n",
       "      <td>-1.856621</td>\n",
       "      <td>2.078384</td>\n",
       "      <td>0.510828</td>\n",
       "      <td>-0.243399</td>\n",
       "      <td>-0.260691</td>\n",
       "      <td>...</td>\n",
       "      <td>0.810408</td>\n",
       "      <td>0.692245</td>\n",
       "      <td>0.150121</td>\n",
       "      <td>-0.260777</td>\n",
       "      <td>0.005183</td>\n",
       "      <td>-0.177847</td>\n",
       "      <td>-0.510060</td>\n",
       "      <td>-0.660533</td>\n",
       "      <td>0.011989</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11475</th>\n",
       "      <td>19899.0</td>\n",
       "      <td>1.338831</td>\n",
       "      <td>-0.547264</td>\n",
       "      <td>0.737389</td>\n",
       "      <td>-0.212383</td>\n",
       "      <td>-1.110039</td>\n",
       "      <td>-0.525744</td>\n",
       "      <td>-0.801403</td>\n",
       "      <td>-0.063672</td>\n",
       "      <td>0.997276</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.139436</td>\n",
       "      <td>-0.074719</td>\n",
       "      <td>0.067055</td>\n",
       "      <td>0.333122</td>\n",
       "      <td>0.379087</td>\n",
       "      <td>-0.268706</td>\n",
       "      <td>-0.002769</td>\n",
       "      <td>0.003272</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211543</th>\n",
       "      <td>138459.0</td>\n",
       "      <td>-1.321976</td>\n",
       "      <td>1.138686</td>\n",
       "      <td>-0.940861</td>\n",
       "      <td>0.154160</td>\n",
       "      <td>0.109802</td>\n",
       "      <td>-0.538822</td>\n",
       "      <td>0.490058</td>\n",
       "      <td>0.513762</td>\n",
       "      <td>-0.493834</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012778</td>\n",
       "      <td>-0.237503</td>\n",
       "      <td>0.008713</td>\n",
       "      <td>-0.767844</td>\n",
       "      <td>-0.397162</td>\n",
       "      <td>0.316379</td>\n",
       "      <td>-0.463125</td>\n",
       "      <td>-0.010589</td>\n",
       "      <td>0.001942</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86293</th>\n",
       "      <td>61167.0</td>\n",
       "      <td>-0.627810</td>\n",
       "      <td>0.918729</td>\n",
       "      <td>1.478453</td>\n",
       "      <td>0.213171</td>\n",
       "      <td>0.933695</td>\n",
       "      <td>1.261486</td>\n",
       "      <td>0.504752</td>\n",
       "      <td>0.404286</td>\n",
       "      <td>-0.939740</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051356</td>\n",
       "      <td>-0.004245</td>\n",
       "      <td>0.090535</td>\n",
       "      <td>-0.964599</td>\n",
       "      <td>-0.522294</td>\n",
       "      <td>0.296733</td>\n",
       "      <td>0.145939</td>\n",
       "      <td>0.110400</td>\n",
       "      <td>0.000973</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122579</th>\n",
       "      <td>76616.0</td>\n",
       "      <td>1.512602</td>\n",
       "      <td>-0.949435</td>\n",
       "      <td>-0.219062</td>\n",
       "      <td>-1.638850</td>\n",
       "      <td>-0.856348</td>\n",
       "      <td>-0.465996</td>\n",
       "      <td>-0.669193</td>\n",
       "      <td>-0.135566</td>\n",
       "      <td>-2.284345</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.558803</td>\n",
       "      <td>-1.377240</td>\n",
       "      <td>0.080444</td>\n",
       "      <td>-0.579511</td>\n",
       "      <td>0.297851</td>\n",
       "      <td>-0.495367</td>\n",
       "      <td>-0.001415</td>\n",
       "      <td>0.003665</td>\n",
       "      <td>0.001358</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152315</th>\n",
       "      <td>97253.0</td>\n",
       "      <td>1.798863</td>\n",
       "      <td>-1.699791</td>\n",
       "      <td>-0.142182</td>\n",
       "      <td>-0.619533</td>\n",
       "      <td>-1.570248</td>\n",
       "      <td>0.083268</td>\n",
       "      <td>-1.501980</td>\n",
       "      <td>0.176287</td>\n",
       "      <td>1.755507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181914</td>\n",
       "      <td>0.351358</td>\n",
       "      <td>0.115638</td>\n",
       "      <td>-0.566188</td>\n",
       "      <td>-0.596200</td>\n",
       "      <td>-0.295152</td>\n",
       "      <td>-0.033616</td>\n",
       "      <td>-0.032471</td>\n",
       "      <td>0.006668</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117952</th>\n",
       "      <td>74887.0</td>\n",
       "      <td>-0.589400</td>\n",
       "      <td>0.747828</td>\n",
       "      <td>1.784781</td>\n",
       "      <td>0.899612</td>\n",
       "      <td>0.257067</td>\n",
       "      <td>-0.001301</td>\n",
       "      <td>0.122334</td>\n",
       "      <td>0.034736</td>\n",
       "      <td>-0.283998</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008910</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>-0.238139</td>\n",
       "      <td>-0.463529</td>\n",
       "      <td>-0.243573</td>\n",
       "      <td>-0.370920</td>\n",
       "      <td>0.086592</td>\n",
       "      <td>0.118084</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "183484  125821.0 -0.323334  1.057455 -0.048341 -0.607204  1.259821 -0.091761   \n",
       "255448  157235.0 -0.349718  0.932619  0.142992 -0.657071  1.169784 -0.733369   \n",
       "244749  152471.0 -1.614711 -2.406570  0.326194  0.665520  2.369268 -1.775367   \n",
       "63919    50927.0 -2.477184  0.860613  1.441850  1.051019 -1.856621  2.078384   \n",
       "11475    19899.0  1.338831 -0.547264  0.737389 -0.212383 -1.110039 -0.525744   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "211543  138459.0 -1.321976  1.138686 -0.940861  0.154160  0.109802 -0.538822   \n",
       "86293    61167.0 -0.627810  0.918729  1.478453  0.213171  0.933695  1.261486   \n",
       "122579   76616.0  1.512602 -0.949435 -0.219062 -1.638850 -0.856348 -0.465996   \n",
       "152315   97253.0  1.798863 -1.699791 -0.142182 -0.619533 -1.570248  0.083268   \n",
       "117952   74887.0 -0.589400  0.747828  1.784781  0.899612  0.257067 -0.001301   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23  \\\n",
       "183484  1.159101 -0.124335 -0.174640  ... -0.207098 -0.433890 -0.261613   \n",
       "255448  1.009985 -0.071069 -0.302083  ... -0.271537 -0.833209 -0.030360   \n",
       "244749 -1.139049  0.329904  0.903813  ...  0.701399  1.134489  0.965054   \n",
       "63919   0.510828 -0.243399 -0.260691  ...  0.810408  0.692245  0.150121   \n",
       "11475  -0.801403 -0.063672  0.997276  ... -0.139436 -0.074719  0.067055   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "211543  0.490058  0.513762 -0.493834  ... -0.012778 -0.237503  0.008713   \n",
       "86293   0.504752  0.404286 -0.939740  ... -0.051356 -0.004245  0.090535   \n",
       "122579 -0.669193 -0.135566 -2.284345  ... -0.558803 -1.377240  0.080444   \n",
       "152315 -1.501980  0.176287  1.755507  ...  0.181914  0.351358  0.115638   \n",
       "117952  0.122334  0.034736 -0.283998  ... -0.008910  0.000367 -0.238139   \n",
       "\n",
       "             V24       V25       V26       V27       V28    Amount  Class  \n",
       "183484 -0.046651  0.211512  0.008297  0.108494  0.161139  0.001557      0  \n",
       "255448  0.490035 -0.404816  0.134350  0.076830  0.175562  0.000077      0  \n",
       "244749  0.640981 -1.801998 -1.041114  0.286285  0.437322  0.003737      0  \n",
       "63919  -0.260777  0.005183 -0.177847 -0.510060 -0.660533  0.011989      0  \n",
       "11475   0.333122  0.379087 -0.268706 -0.002769  0.003272  0.000195      0  \n",
       "...          ...       ...       ...       ...       ...       ...    ...  \n",
       "211543 -0.767844 -0.397162  0.316379 -0.463125 -0.010589  0.001942      0  \n",
       "86293  -0.964599 -0.522294  0.296733  0.145939  0.110400  0.000973      0  \n",
       "122579 -0.579511  0.297851 -0.495367 -0.001415  0.003665  0.001358      0  \n",
       "152315 -0.566188 -0.596200 -0.295152 -0.033616 -0.032471  0.006668      0  \n",
       "117952 -0.463529 -0.243573 -0.370920  0.086592  0.118084  0.000622      0  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c0494775",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CSV 데이터 종속, 독립 변수 분할\n",
    "dataset = df.values\n",
    "X = dataset[:,1:30]\n",
    "\n",
    "Y = dataset[:,30]       #종속변수\n",
    "#훈련, 테스트 데이터 분할\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.15, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9ef0817",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1937/1937 [==============================] - 4s 2ms/step - loss: 0.0024 - accuracy: 0.9997 - val_loss: 0.0049 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00487, saving model to ./model\\01-0.0049.hdf5\n",
      "Epoch 2/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0047 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00487 to 0.00466, saving model to ./model\\02-0.0047.hdf5\n",
      "Epoch 3/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.0051 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.00466\n",
      "Epoch 4/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0051 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00466\n",
      "Epoch 5/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0056 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00466\n",
      "Epoch 6/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0053 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00466\n",
      "Epoch 7/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0065 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00466\n",
      "Epoch 8/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0064 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00466\n",
      "Epoch 9/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.0071 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00466\n",
      "Epoch 10/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0071 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00466\n",
      "Epoch 11/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 7.7612e-04 - accuracy: 0.9998 - val_loss: 0.0072 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00466\n",
      "Epoch 12/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 9.5993e-04 - accuracy: 0.9998 - val_loss: 0.0081 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.00466\n",
      "Epoch 13/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.0084 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.00466\n",
      "Epoch 14/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0092 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.00466\n",
      "Epoch 15/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.0084 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.00466\n",
      "Epoch 16/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 7.7820e-04 - accuracy: 0.9998 - val_loss: 0.0084 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.00466\n",
      "Epoch 17/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 7.3990e-04 - accuracy: 0.9998 - val_loss: 0.0086 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.00466\n",
      "Epoch 18/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 8.2679e-04 - accuracy: 0.9998 - val_loss: 0.0084 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.00466\n",
      "Epoch 19/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 9.2523e-04 - accuracy: 0.9997 - val_loss: 0.0094 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.00466\n",
      "Epoch 20/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 8.1806e-04 - accuracy: 0.9998 - val_loss: 0.0091 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.00466\n",
      "Epoch 21/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 8.0083e-04 - accuracy: 0.9997 - val_loss: 0.0130 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.00466\n",
      "Epoch 22/100\n",
      "1937/1937 [==============================] - 3s 2ms/step - loss: 9.9245e-04 - accuracy: 0.9997 - val_loss: 0.0110 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.00466\n"
     ]
    }
   ],
   "source": [
    "#모델 컴파일 및 학습\n",
    "model.compile(loss='binary_crossentropy',\n",
    "          optimizer='adam',\n",
    "          metrics=['accuracy'])\n",
    "MODEL_DIR = './credit_model/'\n",
    "\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "    \n",
    "modelpath = './model/{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "checkpointer = ModelCheckpoint(filepath = modelpath, monitor = 'val_loss', verbose = 1, save_best_only=True)\n",
    "\n",
    "early_stopping_callback= EarlyStopping(monitor= 'val_loss', patience = 20)\n",
    "\n",
    "history = model.fit(X_train, Y_train, validation_split=0.2, epochs=100, batch_size=100, callbacks = [early_stopping_callback,checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "efc10db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1336/1336 [==============================] - 1s 981us/step - loss: 0.0024 - accuracy: 0.9997\n",
      "[0.002360748825594783, 0.9996957182884216]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f2682f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9621e7c7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0000006503 0.0\n",
      "0.0000000655 0.0\n",
      "0.0000000000 0.0\n",
      "0.0000003681 0.0\n",
      "0.0000004238 0.0\n",
      "0.0000387568 0.0\n",
      "0.0000000001 0.0\n",
      "0.0000021070 0.0\n",
      "0.0000000013 0.0\n",
      "0.0000630336 0.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print('%.10f' % predict[i], Y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "34a5aa75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "425 19 284296 67\n"
     ]
    }
   ],
   "source": [
    "r_count = 0\n",
    "w_count = 0\n",
    "pred_r = 0\n",
    "pred_w = 0\n",
    "tp = 0\n",
    "fp = 0\n",
    "tn = 0\n",
    "fn = 0\n",
    "for index, i in enumerate(Y):\n",
    "    if i == 1.0:\n",
    "        if (predict[index] > 0.5):\n",
    "            tp += 1\n",
    "        else :\n",
    "            fn += 1\n",
    "    else:\n",
    "        if (predict[index] > 0.5):\n",
    "            fp += 1\n",
    "        else :\n",
    "            tn += 1\n",
    "print(tp, fp, tn, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b98200e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision =\t 0.9572072072072072\n",
      "recall =\t 0.8638211382113821\n"
     ]
    }
   ],
   "source": [
    "print(\"precision =\\t\", tp / (tp + fp))\n",
    "print(\"recall =\\t\", tp / (tp + fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1c9229d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_vloss = history.history['val_loss']\n",
    "y_acc = history.history['accuracy']\n",
    "x_len = numpy.arange(len(y_vloss))\n",
    "plt.plot(x_len, y_vloss, 'o', c='red', markersize=3)\n",
    "plt.plot(x_len, y_acc, 'o', c='blue', markersize=3)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
